{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pruning Experiments",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malraharsh/Pruning-Experiments/blob/master/Pruning_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zN4yVFK5-0Bf",
        "colab": {}
      },
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yJwIonXEVJo6",
        "colab": {}
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "# %load_ext tensorboard\n",
        "\n",
        "# os.mkdir('log')\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyz7BwCxbzCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SHOW = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pbY-KGMPvbW9",
        "colab": {}
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(Train_images, Train_labels), (Test_images, Test_labels) = mnist.load_data()\n",
        "\n",
        "# pct_data = 0.1\n",
        "# top = int(np.ceil(Train_images.shape[0] * pct_data))\n",
        "\n",
        "# (train_images, train_labels), (test_images, test_labels) = (Train_images[:top], Train_labels[:top]), (Test_images[:top], Test_labels[:top])\n",
        "# print(top)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsf6QDBAAIa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_labels = test_images = test_labels = None\n",
        "\n",
        "def change_pct_data(pct_data):    \n",
        "    global train_images, train_labels, test_images, test_labels    \n",
        "    top = int(np.ceil(Train_images.shape[0] * pct_data))\n",
        "    (train_images, train_labels), (test_images, test_labels) = (Train_images[:top], Train_labels[:top]), (Test_images[:top], Test_labels[:top])\n",
        "    print(f\"No of data - {top}\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB25l8eRC6oH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_images, train_labels, test_images, test_labels):\n",
        "\n",
        "    # Normalize the input image so that each pixel value is between 0 to 1.\n",
        "    train_images = train_images.copy() / 255.0\n",
        "    test_images = test_images.copy() / 255.0\n",
        "\n",
        "    # Define the model architecture.\n",
        "    model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    # Train the digit classification model\n",
        "    model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=1,\n",
        "    validation_split=0.1,\n",
        "    )\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "    history.history['test_loss'] = [test_loss]\n",
        "    history.history['test_acc'] = [test_accuracy]\n",
        "\n",
        "    if SHOW:\n",
        "        # _, baseline_train_accuracy = model.evaluate(\n",
        "        # train_images, train_labels, verbose=0)\n",
        "\n",
        "        # print('Baseline train accuracy:', baseline_train_accuracy*100)\n",
        "\n",
        "        print('Baseline test accuracy:', baseline_test_accuracy*100)\n",
        "\n",
        "        # print('Baseline difference:', (baseline_train_accuracy - baseline_test_accuracy)*100)\n",
        "\n",
        "    return model, history.history\n",
        "    \n",
        "\n",
        "def prune(train_images, train_labels, model):\n",
        "\n",
        "    # Compute end step to finish pruning after 2 epochs.\n",
        "    batch_size = 128\n",
        "    epochs = 1\n",
        "    validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "    num_images = train_images.shape[0] * (1 - validation_split)\n",
        "    end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "    # Define model for pruning.\n",
        "    pruning_params = {\n",
        "          'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                                   final_sparsity=0.80,\n",
        "                                                                   begin_step=0,\n",
        "                                                                   end_step=end_step)\n",
        "    }\n",
        "\n",
        "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "    # `prune_low_magnitude` requires a recompile.\n",
        "    model_for_pruning.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model_for_pruning.summary()\n",
        "\n",
        "    callbacks = [\n",
        "      tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    #   tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "    ]\n",
        "\n",
        "    history = model_for_pruning.fit(train_images, train_labels,\n",
        "                      batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                      callbacks=callbacks)\n",
        "    \n",
        "    test_loss, test_accuracy = model_for_pruning.evaluate(test_images, test_labels, verbose=0)\n",
        "    history.history['test_loss'] = [test_loss]\n",
        "    history.history['test_acc'] = [test_accuracy]\n",
        "\n",
        "    if SHOW:\n",
        "        print('Pruned test accuracy:', model_for_pruning_accuracy)\n",
        "\n",
        "    return model_for_pruning, history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8isH01mTSZ0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIyrGM-rBkkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_train(test_pct):\n",
        "    train_x, val_x, train_y, val_y = train_test_split(train_images, train_labels, test_size=test_pct, stratify=train_labels)\n",
        "    model, info_train = train(train_x, train_y, val_x, val_y)\n",
        "    _, info_prune = prune(train_x, train_y, model)\n",
        "    return info_train, info_prune"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RtTs_t9Bkfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_info(dic, pct, info):\n",
        "    global z\n",
        "    z=dic\n",
        "    # print(list(dic.items()), '----')\n",
        "    dic = {k:v[-1] for k, v in dic.items()}\n",
        "    dic['percentage'] = pct\n",
        "    return info.append(dic, ignore_index=True)   \n",
        "\n",
        "def save(df, name, pct_data):\n",
        "    df.to_csv(f'log/info-{name}-{pct_data*100}%.csv')\n",
        "\n",
        "def full_pct_data(pct_data): #pct of full data\n",
        "    global z\n",
        "    change_pct_data(pct_data) \n",
        "    df_info_train = pd.DataFrame()\n",
        "    df_info_prune = pd.DataFrame()\n",
        "\n",
        "    for p in range(10, 99, 90):\n",
        "        print(f'\\n Percentage is {p} \\n')\n",
        "\n",
        "        test_p = 1 - p/100\n",
        "        info_train, info_prune = do_train(test_p)\n",
        "        z = info_train\n",
        "\n",
        "        df_info_train = add_info(info_train, 1 - test_p, df_info_train)\n",
        "        df_info_prune = add_info(info_prune, 1 - test_p, df_info_prune)\n",
        "\n",
        "    save(df_info_train, 'train', pct_data)\n",
        "    save(df_info_prune, 'prune', pct_data)\n",
        "\n",
        "    # df_info.plot.scatter(x='percentage', y='accuracy')\n",
        "    # return df_info    \n",
        "\n",
        "full_pct_data(0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHk9KHa6DNeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8oW9_fzIQBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "711d1b53-f203-4073-b886-839e6edcc182"
      },
      "source": [
        "{k:v[-1] for k, v in z.items()}"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.09259258955717087,\n",
              " 'loss': 2.3262572288513184,\n",
              " 'test_acc': 0.20370370149612427,\n",
              " 'test_loss': 2.2623438835144043,\n",
              " 'val_accuracy': 0.1666666716337204,\n",
              " 'val_loss': 2.432265520095825}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFdQij7lX-91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}